{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dff84fdf",
   "metadata": {},
   "source": [
    "---\n",
    "title: Problem Formulation\n",
    "math:\n",
    "  '\\abs': '\\left\\lvert #1 \\right\\rvert'\n",
    "  '\\Set': '\\left\\{ #1 \\right\\}'\n",
    "  '\\mc': '\\mathcal{#1}'\n",
    "  '\\M': '\\boldsymbol{#1}'\n",
    "  '\\R': '\\mathsf{#1}'\n",
    "  '\\RM': '\\boldsymbol{\\mathsf{#1}}'\n",
    "  '\\op': '\\operatorname{#1}'\n",
    "  '\\E': '\\op{E}'\n",
    "  '\\d': '\\mathrm{\\mathstrut d}'\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1856d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5542f3ad",
   "metadata": {},
   "source": [
    "## Mutual information estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54003b6e",
   "metadata": {},
   "source": [
    "**How to formulate the problem of mutual information estimation?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3a8bc3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The problem of estimating the mutual information is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98957d0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "::::{prf:definition} Mutual information estimation\n",
    ":label: def:MIE\n",
    "\n",
    "Given $n$ samples\n",
    "\n",
    "$$(\\R{X}_1,\\R{Y}_1),\\dots, (\\R{X}_n,\\R{Y}_n) \\sim P_{\\R{X},\\R{Y}}^n$$ \n",
    "\n",
    "i.i.d. drawn from an *unknown* probability measure $P_{\\R{X},\\R{Y}}$, estimate the *mutual information (MI)*\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "I(\\R{X}\\wedge\\R{Y}) &:= E\\left[\\log \\frac{d P_{\\R{X},\\R{Y}}}{d (P_{\\R{X}} \\times P_{\\R{Y}})}(\\R{X},\\R{Y}) \\right],\n",
    "\\end{align}\n",
    "$$ (eq:MI)\n",
    "\n",
    "which is an expected density ratio of $(\\R{X}, \\R{Y})$ from their joint distribution to the product of their marginal distributions.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac99fdd",
   "metadata": {},
   "source": [
    "Run the following code, which uses `numpy` to \n",
    "- generate i.i.d. samples from a multivariate gaussian distribution, and\n",
    "- store the samples as numpy arrays assigned to `XY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed4ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeded random number generator for reproducibility\n",
    "XY_rng = np.random.default_rng(SEED)\n",
    "\n",
    "# Sampling from an unknown probability measure\n",
    "rho = 1 - 0.19 * XY_rng.random()\n",
    "mean, cov, n = [0, 0], [[1, rho], [rho, 1]], 1000\n",
    "XY = XY_rng.multivariate_normal(mean, cov, n)\n",
    "\n",
    "# The sample is plotted on a scatterplot\n",
    "plt.scatter(XY[:, 0], XY[:, 1], s=2, label=r\"$(x,y):=(\\mathsf{X}_i, \\mathsf{Y}_i)$\")\n",
    "plt.title(r\"Random sample\")\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.ylabel(r\"$y$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6daa20e",
   "metadata": {},
   "source": [
    "::::{seealso}\n",
    ":class: dropdown\n",
    "\n",
    "The official documentations of [`multivariate_normal`][mn] and [`scatter`][sc].\n",
    "\n",
    "[mn]: https://numpy.org/doc/stable/reference/random/generated/numpy.random.multivariate_normal.html\n",
    "[sc]: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html\n",
    "\n",
    "\n",
    "To get help in [JupyterLab](https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html):\n",
    "\n",
    "- **Docstring**: \n",
    "  - Move the cursor to the object and \n",
    "    - click `Help->Show Contextual Help` or\n",
    "    - click `Shift-Tab` if you have limited screen space.\n",
    "\n",
    "- **Directory**:\n",
    "  - Right click on a notebook and choose `New Console for Notebook`. \n",
    "  - Run `dir(obj)` for a previously defined object `obj` to see the available methods/properties of `obj`.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f38c9a",
   "metadata": {},
   "source": [
    "::::{exercise}\n",
    ":label: ex:sampling-distribution\n",
    "\n",
    " What is unknown about the above sampling distribution?\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e482fa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0236982b88bdfd7aaabc1a532eb06a3e",
     "grade": true,
     "grade_id": "unknown-distribution",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e0881",
   "metadata": {},
   "source": [
    "To show the data samples using `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9d107",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "XY_df = pd.DataFrame(XY, columns=[r\"$x$\", r\"$y$\"])\n",
    "XY_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07abce0d",
   "metadata": {},
   "source": [
    "To plot the data using `seaborn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471c99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples_with_kde(df, **kwargs):\n",
    "    \"\"\"\n",
    "    This function creates a PairGrid plot of the input DataFrame with Seaborn,\n",
    "    plotting a scatterplot on the lower triangle, kernel density estimates (KDE)\n",
    "    on the upper triangle and the diagonals.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame to be plotted. Each column is a separate\n",
    "                    data series that will be plotted against each other.\n",
    "\n",
    "    **kwargs: Additional keyword arguments are passed down to the sns.PairGrid()\n",
    "              function.\n",
    "\n",
    "    Returns:\n",
    "    p (PairGrid): A seaborn.PairGrid object for further customization.\n",
    "\n",
    "    See also:\n",
    "    PairGrid allows us to create a grid of subplots using the same plot type to\n",
    "    visualize data.\n",
    "    \"\"\"\n",
    "    p = sns.PairGrid(df, **kwargs)\n",
    "    p.map_lower(sns.scatterplot, s=2)  # scatter plot of samples\n",
    "    p.map_upper(sns.kdeplot)  # kernel density estimate (kde) for joint distribution\n",
    "    p.map_diag(sns.kdeplot)  # kde for marginal distributions\n",
    "    p.fig.subplots_adjust(top=0.9)\n",
    "    return p\n",
    "\n",
    "\n",
    "plot_samples_with_kde(XY_df)\n",
    "plt.suptitle(\"Random sample with density estimates\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd78be",
   "metadata": {},
   "source": [
    "::::{exercise} sample normal distribution\n",
    ":label: ex:sample-gaussian\n",
    "\n",
    "Complete the following code so that `XY_ref` stores the i.i.d. samples of $(\\R{X}',\\R{Y}')$ where $\\R{X}'$ and $\\R{Y}'$ are zero-mean independent gaussian random variables with unit variance.\n",
    "\n",
    ":::{hint}\n",
    ":class: dropdown\n",
    "\n",
    "```python\n",
    "...\n",
    "cov_ref, n_ = ..., n\n",
    "XY_ref = XY_ref_rng_ref.multivariate_normal(mean, ..., n_)\n",
    "...\n",
    "```\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb7d1ef",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39d080289b62e9f9aa5ed76aada6ba2f",
     "grade": false,
     "grade_id": "sampling",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "XY_ref_rng = np.random.default_rng(SEED)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "XY_ref_df = pd.DataFrame(XY_ref, columns=[r\"$x$\", r\"$y$\"])\n",
    "plot_samples_with_kde(XY_ref_df)\n",
    "plt.suptitle(\"Random sample for independent random variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0790ef",
   "metadata": {},
   "source": [
    "## Divergence estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f928f8e2",
   "metadata": {},
   "source": [
    "**Can we generalize the problem further?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff72874",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Estimating MI in [](#def:MIE) may be viewed as a special case of the following problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a3b7d7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "::::{prf:definition} Divergence estimation\n",
    ":label: DE\n",
    "\n",
    "For $P_{\\R{Z}}\\ll P_{\\R{Z}'}$, estimate the Kullback-Leibler (KL) *divergence*\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "D(P_{\\R{Z}}\\|P_{\\R{Z}'}) &:= E\\left[\\log \\frac{d P_{\\R{Z}}}{d P_{\\R{Z}'}}(\\R{Z}) \\right]\n",
    "\\end{align}\n",
    "$$ (eq:D)\n",
    "\n",
    "using \n",
    "- a sequence $\\R{Z}^n:=(\\R{Z}_1,\\dots, \\R{Z}_n) \\sim P_{\\R{Z}}^n$ of i.i.d. samples from $P_{\\R{Z}}$ if $P_{\\R{Z}}$ is unknown, and\n",
    "- a sequence ${\\R{Z}'}^{n'}\\sim P_{\\R{Z}'}^{n'}$ of i.i.d. samples from $P_{\\R{Z}'}$  if $P_{\\R{Z}'}$, is unknown.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aedb26f",
   "metadata": {},
   "source": [
    "The mutual information can be regarded as the KL divergence from the joint distribution to the product distributions, i.e.,\n",
    "\n",
    "$$\n",
    "I(\\R{X}\\wedge \\R{Y}) = D\\left(P_{\\R{X}, \\R{Y}}\\middle\\|P_{\\R{X}}P_{\\R{Y}}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653641ba",
   "metadata": {},
   "source": [
    "::::{prf:remark}\n",
    "\n",
    "- One may further consider the problem of estimating the *density ratio* $\\frac{d P_{\\R{Z}}(z)}{d P_{\\R{Z}'}(z)}$ or estimate the density $\\frac{dP_{\\R{Z}}}{d\\mu}$ defined respective to some reference measure $\\mu\\gg P_{\\R{Z}}$.\n",
    "- Although $\\R{X}^n$ and $\\R{Y}^n$ for MI estimation should have the same length, $\\R{Z}^n$ and ${\\R{Z}'}^{n'}$ for the divergence estimation can have different lengths, i.e., $n \\not\\equiv n'$. Why?[^different-block-length]\n",
    "\n",
    "::::\n",
    "\n",
    "[^different-block-length]: The dependency between $\\R{Z}$ and $\\R{Z}'$ does not affect the divergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef52f3a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Regarding the mutual information as a divergence from joint to product distributions, the problem can be further generalized to estimtate other divergences such as the $f$-divergence:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a637a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "For a function $f\\in {(-\\infty,\\infty]}^{[0,\\infty)}$ strictly [convex](https://en.wikipedia.org/wiki/Convex_function) with $f(1)=0$, the $f$-divergence from $P_{\\R{Z}}$ to $P_{\\R{Z}'}\\gg P_{\\R{Z}}$ is defined as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "D_f(P_{\\R{Z}} \\| P_{\\R{Z}'}) \n",
    "&:=\n",
    "E\\left[f\\left(\\frac{dP_{\\R{Z}}}{dP_{\\R{Z}'}}(\\R{Z}')\\right)\\right].\n",
    "\\end{align}\n",
    "$$ (eq:f-D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ae619",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f223a2fb4cc27443ef79a94de77a5664",
     "grade": true,
     "grade_id": "D",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d7faf2",
   "metadata": {},
   "source": [
    "::::{solution} ex:D\n",
    ":class: dropdown\n",
    "\n",
    ":::{prf:proof}\n",
    ":nonumber: true\n",
    "\n",
    "With $f(u) = u\\log u$,\n",
    "\n",
    "\\begin{align}\n",
    "D_f(P_{\\R{Z}} \\| P_{\\R{Z}'})\n",
    "&= E\\left[\\frac{dP_{\\R{Z}}}{dP_{\\R{Z}'}}(\\R{Z}')\\log \\frac{dP_{\\R{Z}}}{dP_{\\R{Z}'}}(\\R{Z}')\\right]\\\\\n",
    "&= \\int_{z\\in \\Omega_{\\R{Z}}} \\textcolor{gray}{d P_{\\R{Z}'}(z)} \\cdot \\frac{d P_{\\R{Z}}(z)}{\\textcolor{gray}{d P_{\\R{Z}'}(z)}} \\log \\frac{d P_{\\R{Z}}(z)}{d P_{\\R{Z}'}(z)}.\\\\\n",
    "&= E\\left[\\log \\frac{dP_{\\R{Z}}}{dP_{\\R{Z}'}}(\\R{Z})\\right]\\\\\n",
    "\\end{align}\n",
    "\n",
    "where the last equality is by the property of density ratio.\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76065fe7",
   "metadata": {},
   "source": [
    "::::{exercise}\n",
    ":label: ex:D:non-negativity\n",
    "\n",
    "For the $f$-divergence to be called a divergence, it must satisfy the property that $D_f(P_{\\R{Z}}\\|P_{\\R{Z}'})\\geq 0$ with equality iff $P_{\\R{Z}}=P_{\\R{Z}'}$. Prove this using Jensen's inequality and the properties of $f$.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb543406",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb5e6c02c15de7bad4b0126e9349e6fb",
     "grade": true,
     "grade_id": "D-non-negativity",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIML",
   "language": "python",
   "name": "miml"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
